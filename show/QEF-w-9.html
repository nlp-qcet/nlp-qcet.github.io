<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title> Showing Node QEF-w-9  - Taxonomy of Quality Criteria For Evaluations (QCET) Tool</title>
    <style>
        nav a {
            color: #d64161;
            font-size: 3em;
            margin-left: 50px;
            text-decoration: none;
        }
    </style>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>

    <script src="../static/js/app.js"></script>

    <link rel= "stylesheet" type= "text/css" href= "../static/css/app.css">
</head>
<body>
    <nav>
        <a href="#">Taxonomy of Quality Criteria For Evaluations (QCET) Tool</a>
    </nav>
    <hr>
    <div class="content">
        
    <h4> Showing Node QEF-w-9 </h4>
    <div class="pad">
    	<h5>Parent</h5>
				<div id="*Feature of outputs relative to a specified external frame of reference (+/- input), Outputs as a whole" class="taxonomy_node border border-dark rounded-5 border-3 google_light_purple_3 taxonomy_search_node taxonomy_search_node_d_3" style="max-width:1500px;">
					<h5><a class="link-dark" href="./QEF-w.html">QEF-w&nbsp;:&nbsp;*Feature of outputs relative to a specified external frame of reference (+/- input), Outputs as a whole</a></h5>

				</div>
			<br /><h5>Node Details</h5>
			<div id="QEF-w-9" class="taxonomy_node border border-dark rounded-5 border-3 google_light_grey_2 taxonomy_search_node taxonomy_search_node_d_4" style="max-width:1500px;">
				<h5><a class="link-dark" href="./QEF-w-9.html">QEF-w-9&nbsp;:&nbsp;Likelihood According to External Model</a></h5>
				<p>
					<span class='att_key'>Definition:</span><br /><span class='att_value'>A better system produces outputs that are estimated to be more likely by a given external model</span><br/><span class='att_key'>Attestations:</span><br /><span class='att_value'>Yedetore et al., 2023 train various models (5-gram model, LSTMs, Transformers) on child-directed language data, and use perplexity (a standard formulation as well as the word-frequency normalised SLOR metric) to evaluate how well each model captures the basic structure of the training domain, finding that Transformers have the lowest perplexity, the 5-gram model the highest.</span><br/><span class='att_key'>Additional notes and information:</span><br /><span class='att_value'>The more common use of perplexity is in evaluations where <i>low</i> perplexity as computed with a given model is desirable, where it's seen as indicative of `natural' output. However, it can equally be desirable for outputs to have high perplexity, e.g. in situation where a different style from that encapsulated by the model is intended.  [QEF-w-9] Model Perplexity is a Feature-type QC, hence captures both possibilities. Note that various metrics exist for measuring model perplexity including normalised ones such as SLOR.</span>
				</p>
			</div>
		
			<br />
			<h5>Children</h5>
			<ul>
				None
			</ul>
		
    </div>

    </div>
</body>
</html>