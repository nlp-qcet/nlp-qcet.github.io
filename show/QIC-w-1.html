<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title> Showing Node QIC-w-1  - Taxonomy of Quality Criteria For Evaluations (QCET) Tool</title>
    <style>
        nav a {
            color: #d64161;
            font-size: 3em;
            margin-left: 50px;
            text-decoration: none;
        }
    </style>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>

    <script src="../static/js/app.js"></script>

    <link rel= "stylesheet" type= "text/css" href= "../static/css/app.css">
</head>
<body>
    <nav>
        <a href="#">Taxonomy of Quality Criteria For Evaluations (QCET) Tool</a>
    </nav>
    <hr>
    <div class="content">
        
    <h4> Showing Node QIC-w-1 </h4>
    <div class="pad">
    	<h5>Parent</h5>
				<div id="Correctness of outputs relative to input, Outputs as a whole" class="taxonomy_node border border-dark rounded-5 border-3 google_light_purple_3 taxonomy_search_node taxonomy_search_node_d_3" style="max-width:1500px;">
					<h5><a class="link-dark" href="./QIC-w.html">QIC-w&nbsp;:&nbsp;Correctness of outputs relative to input, Outputs as a whole</a></h5>

				</div>
			<br /><h5>Node Details</h5>
			<div id="QIC-w-1" class="taxonomy_node border border-dark rounded-5 border-3 google_light_grey_2 taxonomy_search_node taxonomy_search_node_d_4" style="max-width:1500px;">
				<h5><a class="link-dark" href="./QIC-w-1.html">QIC-w-1&nbsp;:&nbsp;Translation Accuracy</a></h5>
				<p>
					<span class='att_key'>Definition:</span><br /><span class='att_value'>A better system produces translations of the input with fewer translation errors</span><br/><span class='att_key'>Elicitation:</span><br /><span class='att_value'><i>Intrinsic, subjective, relative</i>: Which of these texts has fewer translation errors?<br /><i>Intrinsic, subjective, absolute</i>: To what degree is this text free of translation errors?</span><br/><span class='att_key'>Attestations:</span><br /><span class='att_value'><a href="https://aclanthology.org/2020.coling-main.444/">PopoviÄ‡, 2020</a> asked annotators to identify and mark up word spans in machine-translated text whose meaning differed from the input text, then investigated different ways of numerically aggregating the annotations.</span><br/><span class='att_key'>Additional notes and information:</span><br /><span class='att_value'>When assessed by human evaluators, Translation Accuracy is often broken down into different error types which are assessed (and sometimes reported) separately. However, such error taxonomies differ too widely in granularity and meaning between papers to be incorporated here as sub-QCs. Among metrics, BLEU (created for MT) works particularly well, especially when assessed against multiple target output translations per input.</span>
				</p>
			</div>
		
			<br />
			<h5>Children</h5>
			<ul>
				None
			</ul>
		
    </div>

    </div>
</body>
</html>